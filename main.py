# âœ… main.py - Google Vision API + GPT ì—°ë™

from fastapi import FastAPI, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
import requests
import openai
import base64
import os
import tempfile
import json 

# ====== í™˜ê²½ë³€ìˆ˜ ì„¤ì • ======
openai.api_key = os.getenv("OPENAI_API_KEY")
GOOGLE_API_KEY = os.getenv("GOOGLE_VISION_API_KEY")

# ====== FastAPI ì´ˆê¸°í™” ======
app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ====== Google Vision OCR í•¨ìˆ˜ ======
def call_google_vision(image_path):
    with open(image_path, "rb") as f:
        img_base64 = base64.b64encode(f.read()).decode("utf-8")

    body = {
        "requests": [
            {
                "image": {"content": img_base64},
                "features": [{"type": "TEXT_DETECTION"}]
            }
        ]
    }

    response = requests.post(
        f"https://vision.googleapis.com/v1/images:annotate?key={GOOGLE_API_KEY}",
        json=body
    )

    result = response.json()
    #print("ğŸ“¦ Vision API ì‘ë‹µ:", json.dumps(result, indent=2, ensure_ascii=False))
    try:
        # 1ìˆœìœ„: fullTextAnnotation
        if 'fullTextAnnotation' in result['responses'][0]:
            return result['responses'][0]['fullTextAnnotation']['text']
        # 2ìˆœìœ„: textAnnotations
        elif 'textAnnotations' in result['responses'][0]:
            return result['responses'][0]['textAnnotations'][0]['description']
        else:
            return "OCR ì‹¤íŒ¨ ë˜ëŠ” í…ìŠ¤íŠ¸ ì¸ì‹ ë¶ˆê°€"
    except:
        return "OCR ì‹¤íŒ¨ ë˜ëŠ” í…ìŠ¤íŠ¸ ì¸ì‹ ë¶ˆê°€"

# ====== GPT ì¶”ì¶œ í”„ë¡¬í”„íŠ¸ ======
def extract_inbody_with_gpt(ocr_text):
    prompt = f"""
ë‹¤ìŒì€ ì¸ë°”ë”” ê²€ì‚¬ ê²°ê³¼ì§€ì—ì„œ OCRë¡œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤: \n\n{ocr_text}\n\n

ì´ ì¤‘ì—ì„œ ë‹¤ìŒ ìˆ˜ì¹˜ë§Œ ì •í™•íˆ ì°¾ì•„ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”:
- ì²´ì¤‘(kg): weight
- ê³¨ê²©ê·¼ëŸ‰(kg): skeletalMuscle
- ì²´ì§€ë°©ëŸ‰(kg): bodyFat

â— ë‹¨, ì•„ë˜ì™€ ê°™ì€ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”. ìˆ«ìëŠ” 0ì´ ì•„ë‹Œ ì´ìƒ 00.0ì´ ì•„ë‹Œ **ìœ íš¨í•œ ë¶€ë™ì†Œìˆ˜ì  ìˆ«ì**ë¡œ ì‘ì„±í•˜ì„¸ìš”.

ì˜ˆì‹œ:
{{
  "weight": 65.4,
  "skeletalMuscle": 28.2,
  "bodyFat": 12.7
}}
    """.strip()

    completion = openai.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}],
        temperature=0
    )

    return completion.choices[0].message.content

# ====== ì—…ë¡œë“œ ì—”ë“œí¬ì¸íŠ¸ ======
@app.post("/extract_inbody")
async def extract(file: UploadFile = File(...)):
    # ì´ë¯¸ì§€ ì„ì‹œ ì €ì¥
    with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as tmp:
        tmp.write(await file.read())
        tmp_path = tmp.name

    # 1. Google OCR í˜¸ì¶œ
    ocr_text = call_google_vision(tmp_path)
    #print("OCR í…ìŠ¤íŠ¸:\n", ocr_text)

    # 2. GPTì—ê²Œ ìˆ˜ì¹˜ ì¶”ì¶œ ìš”ì²­
    try:
        gpt_response = extract_inbody_with_gpt(ocr_text)
        return {"success": True, "data": gpt_response}
    except Exception as e:
        return {"success": False, "error": str(e), "ocr_text": ocr_text}
